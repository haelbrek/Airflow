# Airflow 
Ce projet est donc un exemple d'ingénierie de données, qui implique différentes étapes pour extraire, transformer et stocker des données en utilisant des outils et des technologies spécifiques. Voici les étapes clés du projet :

1) Extraction de données à partir de Twitter API : Dans cette étape, les données seront extraites de l'API Twitter à l'aide de Python. 

2) Transformation des données : Une fois les données extraites, elles seront transformées à l'aide de Python pour les rendre prêtes à être stockées ou analysées. Cela peut inclure la suppression de données inutiles, la normalisation des données, la conversion de formats de données, etc.

3) Déploiement du code sur Airflow/EC2 : Airflow est un outil open source pour la gestion des workflows de données, qui peut être utilisé pour orchestrer les différentes étapes de traitement de données. 

4) Stockage des données sur Amazon S3 : Une fois que les données ont été traitées et transformées, le résultat final sera stocké sur Amazon S3, un service de stockage d'objets dans le cloud d'AWS. Les données stockées peuvent ensuite être utilisées pour des analyses ultérieures ou des visualisations de données.




